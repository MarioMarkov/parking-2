{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "# Replace 'annotations_file_path' with the path to your COCO annotations file\n",
    "coco = COCO(\"./inference_coco/result.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=256, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.image_utils import extract_bndbox_values\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import os\n",
    "from utils.image_utils import mAlexNet\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    \n",
    "print(f\"Using {device}\")\n",
    "\n",
    "model = \"alex\" #m_alex\n",
    "image_dir= \"./inference/images\"\n",
    "annotation_dir= \"./inference/Annotations\"\n",
    "model_dir = \"./models/final_alex_net_both.pth\"\n",
    "predicted_dir = \"./predicted_images\"\n",
    "\n",
    "if not os.path.isdir(predicted_dir):\n",
    "    os.mkdir(predicted_dir)\n",
    "\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "if model == \"m_alex\":\n",
    "    model = mAlexNet()\n",
    "elif model  == \"alex\":\n",
    "    model = models.alexnet(weights=\"IMAGENET1K_V1\")\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.5, inplace=False),\n",
    "        nn.Linear(in_features=9216, out_features=256, bias=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5, inplace=False),\n",
    "        nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(in_features=128, out_features=1, bias=True),\n",
    "    )\n",
    "else:\n",
    "    raise Exception(\"Not a valid model type\")\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(model_dir, map_location=torch.device(device))\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_patch(patch,transform):\n",
    "    img = transform(patch)\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    with torch.no_grad():                \n",
    "        outputs = model(img)\n",
    "        #print(outputs)\n",
    "        #proba_max, preds = torch.max(outputs, 1)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "        is_busy = preds[0]\n",
    "        return is_busy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"./inference_coco\"    \n",
    "coco_images = coco.loadImgs(coco.getImgIds())\n",
    "\n",
    "id_paths = {}\n",
    "for image in coco_images:\n",
    "    id_paths[image[\"id\"]] = os.path.join(images_dir, image['file_name'])\n",
    "    # id_paths[image.id] = image[\"file_name\"]\n",
    "\n",
    "for img_id, img_path in  id_paths.items():\n",
    "    # whole image \n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    # Load annotations for the current image\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "    annotations = coco.loadAnns(ann_ids)\n",
    "    \n",
    "    # Create a drawing object\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # make the mask \n",
    "    mask = Image.new('1', (img.width, img.height), 0)\n",
    "    result = Image.new('RGB', (img.width, img.height))\n",
    "    # go over the annotations\n",
    "    for ann in annotations:      \n",
    "        #cuts the polygon\n",
    "        ImageDraw.Draw(mask).polygon(ann['segmentation'][0], outline=1, fill=1)\n",
    "        \n",
    "        \n",
    "        # Apply the mask to the image\n",
    "        \n",
    "        result.paste(img, mask=mask)\n",
    "\n",
    "        # Find bounding box of the object\n",
    "        bbox = mask.getbbox()\n",
    "\n",
    "        # Crop the image to the bounding box\n",
    "        cropped_patch = result.crop(bbox)\n",
    "        \n",
    "        is_busy = predict_patch(patch=cropped_patch, transform=transform)\n",
    "        color = (255, 0, 0) if is_busy.item() == 1 else (0, 255, 0)\n",
    "        draw.polygon(ann['segmentation'][0], outline=color, width=2)\n",
    "  \n",
    "    img.save(f\"output_{img_id}.png\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'output_dir' with the directory where you want to save the patches\n",
    "output_dir = 'output_patches'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for ann_id in coco.getAnnIds():\n",
    "    ann = coco.loadAnns(ann_id)[0]\n",
    "    image_id = ann['image_id']\n",
    "    image_info = coco.loadImgs(image_id)[0]\n",
    "    image_path = os.path.join('./inference_coco', image_info['file_name'])\n",
    "\n",
    "    \n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Create a binary mask from the polygon\n",
    "    mask = Image.new('1', (img.width, img.height), 0)\n",
    "    #cuts the polygon\n",
    "    ImageDraw.Draw(mask).polygon(ann['segmentation'][0], outline=1, fill=1)\n",
    "    \n",
    "    \n",
    "    # Apply the mask to the image\n",
    "    result = Image.new('RGB', (img.width, img.height))\n",
    "    result.paste(img, mask=mask)\n",
    "\n",
    "    # Find bounding box of the object\n",
    "    bbox = mask.getbbox()\n",
    "\n",
    "    # Crop the image to the bounding box\n",
    "    cropped_patch = result.crop(bbox)\n",
    "\n",
    "    # Save the patch\n",
    "    patch_filename = f\"{ann_id}_patch.jpg\"\n",
    "    patch_path = os.path.join(output_dir, patch_filename)\n",
    "    cropped_patch.save(patch_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
